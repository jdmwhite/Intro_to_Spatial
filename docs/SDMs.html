<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Species Distribution Models</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Making_a_map.html">Making a map</a>
</li>
<li>
  <a href="Land_cover_change.html">Land cover change</a>
</li>
<li>
  <a href="NDVI_time_series.html">NDVI time series</a>
</li>
<li>
  <a href="SDMs.html">SDMs</a>
</li>
<li>
  <a href="Extras.html">Extras</a>
</li>
<li>
  <a href="Resources.html">Additional Resources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Species Distribution Models</h1>

</div>


<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('right', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<p>Note: thank you to Geethen Singh for an earlier version of this
practical.</p>
<div id="learning-objectives" class="section level3">
<h3>Learning objectives</h3>
<ol style="list-style-type: decimal">
<li>Define a calibration area</li>
<li>Process environmental covariate data</li>
<li>Process species presence data</li>
<li>Create pseudo-absence species points</li>
<li>Account for spatial autocorrelation with spatial blocks</li>
<li>Fit a random forest model</li>
<li>Estimate model accuracy</li>
<li>Determine variable importance</li>
<li>Visualise variable response curves</li>
<li>Produce a habitat suitability prediction</li>
</ol>
</div>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>Species Distribution models (SDMs, also called habitat suitability
models or ecological niche models, depending on the goal) involves the
identification of areas of likely species occurrence by learning a
relationship between known occurrences and environmental variables
(covariates). The ‘learning’ of species-environment relationships is
accomplished by machine learning algorithms. For this short course, the
inner-workings of these algorithms are beyond the scope of our available
time. There are many papers describing SDMs, but if you are new to the
field, this <a
href="https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.110308.120159?casa_token=ZCcYcz4kym4AAAAA:PPSNWmUn0wy2Ieu6nVwpzX37f-67fnkVMMxfAUk74Peu01XafOnSf-SF0VuCL24WMwDu4koUzR2wFyg">Elith
&amp; Leathwick 2009</a> paper is a good start.</p>
<p>SDMs are used for a range of purposes, not limited to understanding
drivers of species distributions, conservation planning and risk
forecasting. This tutorial is likely to be challenging for a beginner in
spatial analysis, but is designed to try to balance thoroughness with
simplicity.</p>
<p>Our overall goal is to produce a prediction map of the most suitable
habitat for a species of interest and to better understand the
environmental drivers behind its current distribution. Along the way, we
will carefully process our data to make sure we have the best inputs and
then provide a model evaluation procedure to determine how robust our
findings are.</p>
</div>
<div id="tutorial" class="section level3">
<h3>Tutorial</h3>
<p>We will be using two new-ish R packages for running species
distribution models: <code>flexSDM</code> and <code>SDMtune</code>.
These packages have several features, which are useful in processing and
modeling our SDM data. We will then use <code>blockCV</code> to create a
spatial blocking space to improve the robustness of our findings. Most
of the other packages, you should be familiar with by now.</p>
<pre class="r"><code>#### Install.packages ----
# install.packages(&#39;raster&#39;)
# install.packages(&#39;remotes&#39;)
# devtools::install_github(&quot;sjevelazco/flexsdm&quot;)
# Select 3 and then No
# install.packages(&#39;corrplot&#39;)
# install.packages(&#39;blockCV&#39;)
# install.packages(&#39;SDMtune&#39;)

#### Load libraries ----
library(terra) # raster manipulation
library(rnaturalearth) # country boundaries
library(tidyverse) # data manipulation and plotting
library(corrplot) # correlation plots
library(blockCV) # spatial block for cross-validation
library(sf) # vector manipulation
library(flexsdm) # SDM package
library(SDMtune) # SDM package
library(patchwork) # combine ggplots</code></pre>
<div id="load-in-data" class="section level4">
<h4>Load in data</h4>
<p>We will be using the Protea roupelliae locality data that we used in
the <strong>Making a map</strong> tutorial. This data has already been
processed and cleaned to remove spurious locations.</p>
<p>We will download data for all countries that overlap with the species
localities and then merge these together to make a single country
boundary.</p>
<p>Lastly we will be using the WorldClim data as our environmental
covariates. This can be downloaded using the <code>raster</code> package
or loaded in directly from file.</p>
<pre class="r"><code>#### Load in data ----
# Read species data 
protea &lt;- vect(&quot;output/files/making_a_map/p_roup_gbif.shp&quot;)
# download and load SA boundary
sern_a &lt;- ne_countries(scale = &#39;medium&#39;, country = c(&#39;South Africa&#39;, &#39;Lesotho&#39;, &#39;Swaziland&#39;), returnclass = &#39;sf&#39;)
# dissolve to outer boundary
sern_a %&gt;% group_by(level) %&gt;% summarise() %&gt;% vect() -&gt; sern_a_dissolve
# Download bioclim data
# r &lt;- rast(raster::getData(&quot;worldclim&quot;,var=&quot;bio&quot;,res=5))
# returns 19 variables
# or alternatively load from disk
r &lt;- rast(&quot;data/sdm/worldclim.tif&quot;)</code></pre>
<p>Let’s plot out our species and area of interest. For some reason, a
few border lines remain in our country border file - this won’t impact
our modeling going forward.</p>
<pre class="r"><code>#### Visualise raw data ----
plot(r[[1]])
plot(sern_a_dissolve, add = T)
plot(protea, add=T)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Again, we would like to exclude Marion Island, so crop the country
boundary data to a reasonable extent.</p>
<pre class="r"><code>#### Edit extent of Sern A vector 
plot(sern_a_dissolve)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>sern_a_dissolve &lt;- crop(sern_a_dissolve, ext(15, 33, -35, -20))
plot(sern_a_dissolve)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<p>Check and fix the projections.</p>
<pre class="r"><code>#### Check projections ----
crs(r) == crs(protea)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>crs(r) == crs(sern_a_dissolve)</code></pre>
<pre><code>## [1] FALSE</code></pre>
<pre class="r"><code>sern_a_dissolve &lt;- project(sern_a_dissolve, r)
protea &lt;- project(protea, r)
crs(r) == crs(sern_a_dissolve)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<pre class="r"><code>crs(r) == crs(protea)</code></pre>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="calibration-area" class="section level4">
<h4>Calibration area</h4>
<p>It is really important to only predict our habitat suitability to a
region where the species could feasibly occur. So instead of using the
whole of southern Africa, we will limit this to a calibration area
around our species localities within a 150km buffer zone.</p>
<pre class="r"><code>#### Calibration area ----
# Create a 150km buffer around our species points to create a prediction region
ca_protea &lt;- calib_area(data = as.data.frame(protea),
                        x = &#39;lon&#39;, y = &#39;lat&#39;,
                        method = c(&#39;buffer&#39;, width = 150000),
                        crs = crs(protea))

# Plot it out to see if this works
par(mfrow = c(1,1))
plot(ca_protea)
plot(protea, add = TRUE)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We can then clean this up to only be focused on the countries where
this species occurs:</p>
<pre class="r"><code># Intersect this with our country boundary to remove areas in the ocean
aoi &lt;- terra::intersect(ca_protea, sern_a_dissolve)
plot(ca_protea)
plot(aoi, col = &#39;red&#39;, add = TRUE)
plot(protea, add = TRUE)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="process-the-covariate-data" class="section level4">
<h4>Process the covariate data</h4>
<p>There are a few steps we need to take to clean up our worldclim data.
First we crop and mask the covariates to our area of interest.</p>
<pre class="r"><code># Mask the covariates to the area of interest
covariates &lt;- mask(crop(r, aoi), aoi)
plot(covariates[[1]])
plot(aoi, add = TRUE)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We then rename the bands to more sensible, readable names.</p>
<pre class="r"><code># rename the worldclim bands to more reasonable names
names(covariates)</code></pre>
<pre><code>##  [1] &quot;bio1&quot;  &quot;bio2&quot;  &quot;bio3&quot;  &quot;bio4&quot;  &quot;bio5&quot;  &quot;bio6&quot;  &quot;bio7&quot;  &quot;bio8&quot;  &quot;bio9&quot; 
## [10] &quot;bio10&quot; &quot;bio11&quot; &quot;bio12&quot; &quot;bio13&quot; &quot;bio14&quot; &quot;bio15&quot; &quot;bio16&quot; &quot;bio17&quot; &quot;bio18&quot;
## [19] &quot;bio19&quot;</code></pre>
<pre class="r"><code>names(covariates) &lt;- c(&quot;mean_ann_t&quot;,&quot;mean_diurnal_t_range&quot;,&quot;isothermality&quot;, &quot;t_seas&quot;, &#39;max_t_warm_m&#39;,&#39;min_t_cold_m&#39;,&quot;t_ann_range&quot;,&#39;mean_t_wet_q&#39;,&#39;mean_t_dry_q&#39;,&#39;mean_t_warm_q&#39;,&#39;mean_t_cold_q&#39;,&#39;ann_p&#39;, &#39;p_wet_m&#39;,&#39;p_dry_m&#39;,&#39;p_seas&#39;,&#39;p_wet_q&#39;,&#39;p_dry_q&#39;,&#39;p_warm_q&#39;,&#39;p_cold_q&#39;)
names(covariates)</code></pre>
<pre><code>##  [1] &quot;mean_ann_t&quot;           &quot;mean_diurnal_t_range&quot; &quot;isothermality&quot;       
##  [4] &quot;t_seas&quot;               &quot;max_t_warm_m&quot;         &quot;min_t_cold_m&quot;        
##  [7] &quot;t_ann_range&quot;          &quot;mean_t_wet_q&quot;         &quot;mean_t_dry_q&quot;        
## [10] &quot;mean_t_warm_q&quot;        &quot;mean_t_cold_q&quot;        &quot;ann_p&quot;               
## [13] &quot;p_wet_m&quot;              &quot;p_dry_m&quot;              &quot;p_seas&quot;              
## [16] &quot;p_wet_q&quot;              &quot;p_dry_q&quot;              &quot;p_warm_q&quot;            
## [19] &quot;p_cold_q&quot;</code></pre>
<p>Rasters are often stored with a scaling factor to save on file size.
For the temperature data, we will need to rescale these back to their
original values.</p>
<pre class="r"><code># Re-scale temperature values
covariates[[c(1:2,5:11)]] &lt;- covariates[[c(1:2,5:11)]]/10
covariates[[3:4]] &lt;- covariates[[3:4]]/100</code></pre>
</div>
<div id="check-for-colinearity" class="section level4">
<h4>Check for colinearity</h4>
<p>Of these 19 different bioclimatic variables, several of them provide
us with very similar, redundant information. To avoid this, we can check
for collinearity above a certain threshold (0.7 is commonly used).</p>
<pre class="r"><code># Using Pearson correlation
cov_colin &lt;- correct_colinvar(covariates, method = c(&#39;pearson&#39;, th = &quot;0.7&quot;))
# Take a look at the correlations using corrplot
corrplot(cov_colin$cor_table, tl.cex = 0.6)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>It is a baseplot output, so save it to file using a graphics
function, such as <code>pdf()</code>. Remember to turn the plotting
device off using <code>dev.off()</code>.</p>
<pre class="r"><code>pdf(&#39;output/figs/SDM/corr_plot.pdf&#39;, width = 8, height = 6)
corrplot(cov_colin$cor_table, tl.cex = 0.6)
dev.off()</code></pre>
<pre><code>## quartz_off_screen 
##                 2</code></pre>
<pre class="r"><code># Show which variables are correlated
cov_colin$cor_variables</code></pre>
<pre><code>## $mean_ann_t
## [1] &quot;max_t_warm_m&quot;  &quot;min_t_cold_m&quot;  &quot;mean_t_wet_q&quot;  &quot;mean_t_dry_q&quot; 
## [5] &quot;mean_t_warm_q&quot; &quot;mean_t_cold_q&quot;
## 
## $mean_diurnal_t_range
## [1] &quot;t_seas&quot;      &quot;t_ann_range&quot; &quot;p_dry_m&quot;     &quot;p_dry_q&quot;     &quot;p_cold_q&quot;   
## 
## $isothermality
## character(0)
## 
## $t_seas
## [1] &quot;mean_diurnal_t_range&quot; &quot;min_t_cold_m&quot;         &quot;t_ann_range&quot;         
## 
## $max_t_warm_m
## [1] &quot;mean_ann_t&quot;    &quot;mean_t_wet_q&quot;  &quot;mean_t_dry_q&quot;  &quot;mean_t_warm_q&quot;
## [5] &quot;mean_t_cold_q&quot;
## 
## $min_t_cold_m
## [1] &quot;mean_ann_t&quot;    &quot;t_seas&quot;        &quot;t_ann_range&quot;   &quot;mean_t_wet_q&quot; 
## [5] &quot;mean_t_dry_q&quot;  &quot;mean_t_warm_q&quot; &quot;mean_t_cold_q&quot;
## 
## $t_ann_range
## [1] &quot;mean_diurnal_t_range&quot; &quot;t_seas&quot;               &quot;min_t_cold_m&quot;        
## 
## $mean_t_wet_q
## [1] &quot;mean_ann_t&quot;    &quot;max_t_warm_m&quot;  &quot;min_t_cold_m&quot;  &quot;mean_t_dry_q&quot; 
## [5] &quot;mean_t_warm_q&quot; &quot;mean_t_cold_q&quot;
## 
## $mean_t_dry_q
## [1] &quot;mean_ann_t&quot;    &quot;max_t_warm_m&quot;  &quot;min_t_cold_m&quot;  &quot;mean_t_wet_q&quot; 
## [5] &quot;mean_t_warm_q&quot; &quot;mean_t_cold_q&quot;
## 
## $mean_t_warm_q
## [1] &quot;mean_ann_t&quot;    &quot;max_t_warm_m&quot;  &quot;min_t_cold_m&quot;  &quot;mean_t_wet_q&quot; 
## [5] &quot;mean_t_dry_q&quot;  &quot;mean_t_cold_q&quot;
## 
## $mean_t_cold_q
## [1] &quot;mean_ann_t&quot;    &quot;max_t_warm_m&quot;  &quot;min_t_cold_m&quot;  &quot;mean_t_wet_q&quot; 
## [5] &quot;mean_t_dry_q&quot;  &quot;mean_t_warm_q&quot;
## 
## $ann_p
## [1] &quot;p_wet_m&quot;  &quot;p_dry_m&quot;  &quot;p_wet_q&quot;  &quot;p_dry_q&quot;  &quot;p_warm_q&quot; &quot;p_cold_q&quot;
## 
## $p_wet_m
## [1] &quot;ann_p&quot;    &quot;p_wet_q&quot;  &quot;p_warm_q&quot;
## 
## $p_dry_m
## [1] &quot;mean_diurnal_t_range&quot; &quot;ann_p&quot;                &quot;p_seas&quot;              
## [4] &quot;p_dry_q&quot;              &quot;p_cold_q&quot;            
## 
## $p_seas
## [1] &quot;p_dry_m&quot;  &quot;p_dry_q&quot;  &quot;p_cold_q&quot;
## 
## $p_wet_q
## [1] &quot;ann_p&quot;    &quot;p_wet_m&quot;  &quot;p_warm_q&quot;
## 
## $p_dry_q
## [1] &quot;mean_diurnal_t_range&quot; &quot;ann_p&quot;                &quot;p_dry_m&quot;             
## [4] &quot;p_seas&quot;               &quot;p_cold_q&quot;            
## 
## $p_warm_q
## [1] &quot;ann_p&quot;   &quot;p_wet_m&quot; &quot;p_wet_q&quot;
## 
## $p_cold_q
## [1] &quot;mean_diurnal_t_range&quot; &quot;ann_p&quot;                &quot;p_dry_m&quot;             
## [4] &quot;p_seas&quot;               &quot;p_dry_q&quot;</code></pre>
<p>We can then select a subset of variables that we will use going
forward. Don’t forget though, that the other removed variables that are
correlated to our selected variables could also likely play an important
role in determining the suitability range of our species.</p>
<pre class="r"><code># Select the subset we want
selected_vars &lt;- c(&#39;min_t_cold_m&#39;, &#39;max_t_warm_m&#39;,&#39;isothermality&#39;,&#39;ann_p&#39;,&#39;p_seas&#39;)

# Subset the covariate data
cov_clean &lt;- covariates[[selected_vars]]
cov_clean</code></pre>
<pre><code>## class       : SpatRaster 
## dimensions  : 127, 81, 5  (nrow, ncol, nlyr)
## resolution  : 0.08333333, 0.08333333  (x, y)
## extent      : 26, 32.75, -32.75, -22.16667  (xmin, xmax, ymin, ymax)
## coord. ref. : lon/lat WGS 84 (EPSG:4326) 
## sources     : memory  
##               memory  
##               memory  
##               ... and 1 more source(s)
## names       : min_t_cold_m, max_t_warm_m, isothermality,   ann_p,  p_seas 
## min values  :        -5.70,        14.60,          0.49,  320.00,   25.00 
## max values  :        13.10,        35.00,          0.65, 1390.00,   95.00</code></pre>
</div>
<div id="presence-filtering" class="section level4">
<h4>Presence filtering</h4>
<p>We can now work on our presence data. To avoid areas that may be
over-sampled with highly clustered points that may create bias in our
model output, we can run a <strong>thinning</strong> function. In this
case, we will use a function <code>flexSDM::occfilt_env()</code> to
avoid points with overly similar environmental covariate values. This
will remove several locality records, but leave us with better data
overall.</p>
<pre class="r"><code># select only the lon/lat and provide a unique ID to each row
protea_df &lt;- as.data.frame(protea) %&gt;% select(lon, lat)
protea_df$id &lt;- 1:nrow(protea_df)

# Run a filter on presence values based on the similarity in values of the environmental covariates
occ_filt_10bin &lt;- occfilt_env(
  data = protea_df,
  x = &#39;lon&#39;,
  y = &#39;lat&#39;,
  id = &#39;id&#39;,
  env_layer = cov_clean,
  nbins = 10 # run ?occfilt_env to find out more on the method
)</code></pre>
<pre><code>## Extracting values from raster ...</code></pre>
<pre><code>## Number of unfiltered records: 244</code></pre>
<pre><code>## Number of filtered records: 103</code></pre>
<pre class="r"><code># This removes ~120 records and only keeps ~100 records due to similarity!

# Plot our old points and new filtered points
par(mfrow = c(1,1))
plot(cov_clean[[1]]); 
points(protea_df, pch = 19, cex = 0.3);
points(occ_filt_10bin[,2:3], pch = 19, cex = 0.3, col = &#39;red&#39;)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre class="r"><code># most of the filtering is happening where the points are spatially clustered...</code></pre>
<p>Save these to a new data frame and then assign a value to indicate
these are presence points (i.e. 1).</p>
<pre class="r"><code># Save the 10 bin environmental filtering
protea_filt_pres &lt;- occ_filt_10bin[,2:3]

# Assign 1 to represent presence
protea_filt_pres$pr_ab &lt;- 1</code></pre>
</div>
<div id="spatial-block-cross-validation" class="section level4">
<h4>Spatial block cross-validation</h4>
<p>We now want to partition our data into different spatial blocks or
“folds” to avoid spatial autocorrelation. This set of function will help
to create spatially similar groups. When we later run our models, we
will then be able to see if our models can predict to areas with
spatially dissimilar values. This is an important step in any model that
has a spatial element to it.</p>
<p>First, run the <code>blockCV::spatialAutoRange()</code> to find what
the recommended size of our spatial blocks should be. This is based on
the similarity in values across each environmental covariate.</p>
<pre class="r"><code># find the range value of block sizes by fitting variograms to each environmental raster to find the effective range of spatial autocorrelation
spat_range &lt;- spatialAutoRange(
  rasterLayer = raster::raster(cov_clean),
  speciesData = st_as_sf(protea_filt_pres, coords = c(&#39;lon&#39;,&#39;lat&#39;), crs = crs(cov_clean)),
  doParallel = TRUE,
  showPlots = TRUE)</code></pre>
<pre><code>## Loading required namespace: rgeos</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code># This suggest ~120km as an appropriate size for our blocks</code></pre>
<p>This suggests a value of approximately 120 km as an appropriate size
for our spatial blocks. We can now assign these blocks to k different
spatial folds. In this case, we chose k = 4 folds as we have a limited
amount of locality points.</p>
<pre class="r"><code># We can now create our spatial folds (k) for later cross-validation
# set the random seed, so this the output is the same across machines
k = 4

spat_blocks1 &lt;- spatialBlock(
  speciesData = st_as_sf(protea_filt_pres, coords = c(&#39;lon&#39;,&#39;lat&#39;), crs = crs(cov_clean)),
  species = &quot;pr_ab&quot;,
  rasterLayer = raster::raster(cov_clean),
  k = k,
  theRange = spat_range$range,
  border = st_as_sf(aoi),
  seed = 101
)</code></pre>
<pre><code>## The best folds was in iteration 55:
##   train_1 test_1
## 1      78     25
## 2      77     26
## 3      79     24
## 4      75     28</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/spatial_block.png&#39;,
       width = 6, height = 5, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
<p>We can now assign the fold IDs back onto our species presence data
frame.</p>
<pre class="r"><code># Assign the folds (or partitions) back onto the presence dataset
protea_filt_pres$folds &lt;- spat_blocks1$foldID
# Each point is now assigned to 1 of 4 partitions
head(protea_filt_pres)</code></pre>
<pre><code>## # A tibble: 6 × 4
##     lon   lat pr_ab folds
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1  28.7 -30.2     1     1
## 2  28.2 -30.8     1     2
## 3  27.8 -26.1     1     3
## 4  29.4 -29.6     1     4
## 5  28.8 -30.4     1     1
## 6  30.9 -24.7     1     2</code></pre>
<p>Check to see how many presences are found within each spatial
fold:</p>
<pre class="r"><code># count the number of presences in each fold
protea_filt_pres %&gt;% group_by(folds) %&gt;% count()</code></pre>
<pre><code>## # A tibble: 4 × 2
## # Groups:   folds [4]
##   folds     n
##   &lt;int&gt; &lt;int&gt;
## 1     1    25
## 2     2    26
## 3     3    24
## 4     4    28</code></pre>
<p>Conver the spatial blocks to a raster, so that we can later extract
this for our pseudo-absence data.</p>
<pre class="r"><code># Rasterize the blocks
grid_env &lt;- rasterize(vect(spat_blocks1$blocks), cov_clean, field = &#39;folds&#39;)</code></pre>
<pre><code>## Warning: [vect] argument &#39;crs&#39; should be a character value</code></pre>
<pre class="r"><code>plot(grid_env)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="create-pseudo-absences" class="section level4">
<h4>Create pseudo-absences</h4>
<p>The creating of pseudo-absence or background points is a crucial step
in many SDMs. Most SDMs require both presence (1) and absence (0) data
to properly evaluate the model accuracy. However, most species data is
presence-only. The way around this is to create artifical points, which
could replicate the effect of having absence points. These are called
<strong>pseudo-absences</strong>. There is a lot of debate on the best
approach for the producing these pseudo-absences as they can have a
major impact on our overall model predictions and evaluation. Read more
about this <a
href="https://www.biorxiv.org/content/10.1101/2022.03.24.485693v1.full">here</a>.</p>
<p>Pseudo-absences can be create randomly, in a equal or
proportionally-stratified manner or several other ways. Here we will use
a proportionally-stratified approach and make sure that each spatial
fold has the same number of both presences and absences by looping over
each iteration of our spatial folds (1:k).</p>
<p>Additionally, we impose a buffer on our pseudo-absence points ot make
sure they are at least 20 km away from our presence points. We could
alternatively use an environmental buffer, where the pseudo-absence
points are placed in sites with a strong environmental dissimilarity
from our presence points. Try out the alternative approach in your own
time.</p>
<pre class="r"><code># We can now create our pseudo-absences and make sure they are evenly spaced across each of our fold grids, based on the number of presence points we have in each fold
# We can also make sure that they are placed away from our presence points by a environmental or distance buffer - here we use a 20 km distance buffer
# pseudo-absences
pa &lt;- lapply(1:k, function(x) {
  sample_pseudoabs(
  data = protea_filt_pres,
  x = &#39;lon&#39;,
  y = &#39;lat&#39;,
  n = sum(protea_filt_pres$folds == x),
  # method = c(&#39;env_const&#39;, env = cov_clean), # constrain to env less suitable places based on bioclim model of protea presences
  # method = &#39;random&#39;,
  method = c(&#39;geo_const&#39;, width = 20000),
  maskval = x,
  rlayer = grid_env,
  calibarea = aoi
)
}) %&gt;% bind_rows() </code></pre>
<p>We then extract the value of each fold for our pseudo-absence points
using our rasterized spatial folds.</p>
<pre class="r"><code># Extract the partition number for each pseudo-absence point
pa &lt;- sdm_extract(data = pa, x = &quot;lon&quot;, y = &quot;lat&quot;, env_layer = grid_env)
head(pa)</code></pre>
<pre><code>## # A tibble: 6 × 4
##     lon   lat pr_ab folds
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  29.7 -25.0     0     1
## 2  29.1 -31.7     0     1
## 3  29.4 -30.8     0     1
## 4  29.1 -31.6     0     1
## 5  30.0 -25.9     0     1
## 6  31.1 -29.2     0     1</code></pre>
<p>Check to see if we have the same number of presence and
pseudo-absence points in each fold:</p>
<pre class="r"><code># Count the number of pseudo-absence &amp; presence points in each fold and see if they are equal
pa %&gt;% group_by(folds) %&gt;% count() == protea_filt_pres %&gt;% group_by(folds) %&gt;% count()</code></pre>
<pre><code>##      folds    n
## [1,]  TRUE TRUE
## [2,]  TRUE TRUE
## [3,]  TRUE TRUE
## [4,]  TRUE TRUE</code></pre>
<p>We can now plot this out to see what it looks like in space. Notice
that the environmentally similar blocks may be found on opposite sides
of our area of interest. This is likely due to the simple nature of our
environmental covariates. If we included different coviarates, we would
get a very different spatial block pattern.</p>
<pre class="r"><code>#### Let&#39;s plot the presences and pseudo-absences and view which folds they fall into
ggplot() +
  geom_sf(data = st_as_sf(aoi), fill = NA) +
  geom_sf(data = st_as_sf(spat_blocks1$blocks)) +
  geom_point(data = rbind(protea_filt_pres, pa), aes(x = lon, y = lat, col = as.factor(folds), pch = as.factor(pr_ab))) +
  labs(colour = &#39;Folds&#39;, shape = &#39;Presence/\nPseudo-absence&#39;) +
  theme_void()</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/folds_and_points.png&#39;,
       width = 6, height = 5, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
</div>
<div id="extract-covariate-values-for-each-point"
class="section level4">
<h4>Extract covariate values for each point</h4>
<p>In most SDM workflows, we could now extract the covariate data for
each point using a function like <code>terra::extract()</code>. To see
this in action, take a look at Tutorial 1 in the Extras Tab. However,
the <code>SDMtune</code> package has specialised data structure called
SWD (Sample with Data), which we will make use of. This is designed to
specifically work together with the <code>train()</code> function that
we will use when building our random forest.</p>
<pre class="r"><code># Prepare a SWD (Sample with Data), which is a class of data specifically used in the SDMtune package
SWDdata &lt;- prepareSWD(
  species = &#39;Protea roupelliae&#39;,
  p = protea_filt_pres[,1:2],
  a = pa[,1:2],
  env = cov_clean
)</code></pre>
<pre><code>## Extracting predictor information for presence locations...</code></pre>
<pre><code>## Extracting predictor information for absence/background locations...</code></pre>
<pre class="r"><code># For some reason ID is included, so we need to remove this...
SWDdata@data &lt;- SWDdata@data[-1]

head(SWDdata@data)</code></pre>
<pre><code>##   min_t_cold_m max_t_warm_m isothermality ann_p p_seas
## 1          0.9         24.8          0.55   743     69
## 2         -1.1         24.3          0.53   767     59
## 3          1.6         27.1          0.55   712     74
## 4         -3.0         22.4          0.52  1031     75
## 5          1.7         24.8          0.58   793     67
## 6          5.1         24.3          0.64  1010     77</code></pre>
</div>
<div id="fit-the-model" class="section level4">
<h4>Fit the model</h4>
<p>We have now thoroughly processed our species and covariate data and
we are finally ready to fit our models.</p>
<p>We will run two different types of models. First one using random
folds (i.e. no spatial component) and secondly one based on our spatial
folds.</p>
<p>For both sets of models, we will use the default settings for a
random forest. Many modeling exercises may suggest hyper-parameter
tuning, which means trying out several iterations of the settings until
finding the best settings for our data. Read up more on how to implement
this in <a
href="https://consbiol-unibern.github.io/SDMtune/articles/articles/tune-hyperparameters.html">SDMtune</a>.</p>
<p>Both models use the <code>SDMtune::train()</code> function. We need
to specify the type of model want to use (run
<code>?SDMtune::train()</code> to view the other model methods), our
<code>SWDdata</code> and our fold structure. It will then train our
model on each training set for each of our folds, which will result in
four separate model outputs.</p>
</div>
<div id="randomforest-with-random-folds" class="section level4">
<h4>RandomForest with random folds</h4>
<pre class="r"><code># We can now fit our models! Let&#39;s first create random folds so that we can compare the output with the spatial blocking folds
rand_folds &lt;- randomFolds(SWDdata, k = 4, seed = 1)

# Run a RandomForest model with default setting and random folds
set.seed(1)
rf_randcv &lt;- train(method = &#39;RF&#39;, data = SWDdata, folds = rand_folds)</code></pre>
<p>We can then run evaluation metrics across each of the four models
using our testing data. We will be using the Area Under Curve (AUC) and
True Skill Statistic (TSS) to evaluate our model performance. As we have
4 folds, this is an average value across all 4 models. AUC values range
from 0 to 1 (with 0.5 being no better than chance). TSS values range
from -1 to 1 (with 0 being no better than chance).</p>
<pre class="r"><code># Check the overall AUC and TSS values
paste0(&#39;Testing AUC: &#39;, round(SDMtune::auc(rf_randcv, test = TRUE),2))</code></pre>
<pre><code>## [1] &quot;Testing AUC: 0.86&quot;</code></pre>
<pre class="r"><code>paste0(&#39;Testing TSS: &#39;, round(SDMtune::tss(rf_randcv, test = TRUE),2))</code></pre>
<pre><code>## [1] &quot;Testing TSS: 0.64&quot;</code></pre>
<p>This model performs really well, with an AUC of 0.86 and TSS of 0.64.
However, we have not accounted for the spatial clustering/distribution
of our points.</p>
<div id="randomforest-with-spatial-folds" class="section level5">
<h5>RandomForest with spatial folds</h5>
<p>When we first ran the <code>blockCV::spatialBlock()</code> function,
we only used presence points and then used to spatial blocks to
proportionately stratify our pseudo-absence data. This meant that there
was no pseudo-absence data included in the <code>spat_blocks1</code>
output. So we will run this function again, this time including the
pseudo-absences.</p>
<p>However, we will make sure that we use our previously
<strong>predefined spatial blocks</strong> - meaning there will be no
change in the spatial block numbering or spatial distribution. All it
does is assign a block value to both the presence <em>and</em>
pseudo-absences.</p>
<pre class="r"><code># Our initial spatial blocking did not include the pseudo-absence data, so let&#39;s re-run the spatialBlock function to include both presence (1) and pseudo-absences (0)
# we can now use our previously predefined blocks
spat_blocks2 &lt;- spatialBlock(speciesData = st_as_sf(bind_rows(protea_filt_pres, pa), coords = c(&#39;lon&#39;,&#39;lat&#39;), crs = crs(cov_clean)), 
                   species = &quot;pr_ab&quot;,
                   rasterLayer = raster::raster(cov_clean)[[1]], 
                   selection = &#39;predefined&#39;,
                   k = k,
                   blocks = spat_blocks1$blocks,
                   foldsCol = &quot;folds&quot;,
                   seed = 101) </code></pre>
<pre><code>##   train_0 train_1 test_0 test_1
## 1      78      78     25     25
## 2      77      77     26     26
## 3      80      79     23     24
## 4      74      75     29     28</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r"><code># View the output
spat_blocks2$folds</code></pre>
<pre><code>## [[1]]
## [[1]][[1]]
##   [1] 130 154 146 137 141  36 140 133  74  56 134  24 132 202  71 201 179 186
##  [19] 198  41 200 195  75  52 157 172  53 171 176  70 170  78 165  44 156 159
##  [37]  81 164  94  80  10  12  61 131  19  31 145   6  59  99 173  11   3  82
##  [55] 162  37  77  23 161 178  17  76 168 155  55  66 166 199  98 184 158 101
##  [73]  28 163 175  93 160 174  92  48  68 169  32 177 167 205  49 182 196 135
##  [91] 143 139  60 144 129  67 148 152 103  95  54  22  87 191 204   8   4  26
## [109]  84  16 181  30  20  64 189  34  83  86  33 188 187 193 203  85 194  29
## [127]  72  88 147  65  42 136 149  73 150  18 151 183  35  14 192  89 190 185
## [145] 206   2 142 138  43   7  79 153 197  50 102 180
## 
## [[1]][[2]]
##  [1] 122  97 104 126  15 110 128 111 117 114  27 108   9  13  90  25 115  91  62
## [20]  96  38  51  58  69 109  21 112 113  63 121 125 120 119 124   1  46  47 118
## [39]   5  45 100  39 107 123 106  40  57 116 127 105
## 
## 
## [[2]]
## [[2]][[1]]
##   [1] 202  71 201 179 186 198  41 200 195  75  52 157 172  53 171 176  70 170
##  [19]  78 165  44 156 159  81 164 122  97 104 126  15 110 128 111 117 114 173
##  [37]  11   3  82 162  37  77  27 108   9  13  90  25 115  91  62  96  38  51
##  [55]  58  69  23 161 178  17  76 168 155  55  66 166 199  98 184 158 101  28
##  [73] 163 175  93 160 174  92  48  68 169  32 177 167 205  49 182 196 103  95
##  [91]  54  22  87 191 204   8   4  26  84  16 181  30  20  64 189  34  83  86
## [109]  33 188 187 193 203  85 194  29 109  21 112 113  63 121 125 120 119 124
## [127]   1  46  47 118   5  45 100 183  35  14 192  89 190 185 206  39 107 123
## [145] 106  40  57 116 127 105 197  50 102 180
## 
## [[2]][[2]]
##  [1] 130 154 146 137 141  36 140 133  74  56 134  24 132  94  80  10  12  61 131
## [20]  19  31 145   6  59  99 135 143 139  60 144 129  67 148 152  72  88 147  65
## [39]  42 136 149  73 150  18 151   2 142 138  43   7  79 153
## 
## 
## [[3]]
## [[3]][[1]]
##   [1] 130 154 146 137 141  36 140 133  74  56 134  24 132 202  71 201 179 186
##  [19] 198  41 200 195 122  97 104 126  94  80  10  12  61 131  19  31 145   6
##  [37]  59  99  15 110 128 111 117 114  27 108   9  13  90  25 115  91  62  96
##  [55]  38  51  58  69 199  98 184 158 205  49 182 196 135 143 139  60 144 129
##  [73]  67 148 152 103  95  54  22  87 191 204   8   4  26  84  16 181  30  20
##  [91]  64 189  34  83  86  33 188 187 193 203  85 194  29 109  21 112 113  63
## [109] 121 125 120 119 124   1  46  47 118   5  45 100  72  88 147  65  42 136
## [127] 149  73 150  18 151 183  35  14 192  89 190 185 206   2 142 138  43   7
## [145]  79 153  39 107 123 106  40  57 116 127 105 197  50 102 180
## 
## [[3]][[2]]
##  [1]  75  52 157 172  53 171 176  70 170  78 165  44 156 159  81 164 173  11   3
## [20]  82 162  37  77  23 161 178  17  76 168 155  55  66 166 101  28 163 175  93
## [39] 160 174  92  48  68 169  32 177 167
## 
## 
## [[4]]
## [[4]][[1]]
##   [1] 130 154 146 137 141  36 140 133  74  56 134  24 132  75  52 157 172  53
##  [19] 171 176  70 170  78 165  44 156 159  81 164 122  97 104 126  94  80  10
##  [37]  12  61 131  19  31 145   6  59  99  15 110 128 111 117 114 173  11   3
##  [55]  82 162  37  77  27 108   9  13  90  25 115  91  62  96  38  51  58  69
##  [73]  23 161 178  17  76 168 155  55  66 166 101  28 163 175  93 160 174  92
##  [91]  48  68 169  32 177 167 135 143 139  60 144 129  67 148 152 109  21 112
## [109] 113  63 121 125 120 119 124   1  46  47 118   5  45 100  72  88 147  65
## [127]  42 136 149  73 150  18 151   2 142 138  43   7  79 153  39 107 123 106
## [145]  40  57 116 127 105
## 
## [[4]][[2]]
##  [1] 202  71 201 179 186 198  41 200 195 199  98 184 158 205  49 182 196 103  95
## [20]  54  22  87 191 204   8   4  26  84  16 181  30  20  64 189  34  83  86  33
## [39] 188 187 193 203  85 194  29 183  35  14 192  89 190 185 206 197  50 102 180</code></pre>
<p>As we can see, we have 4 folds In each of these we have our training
data [[1]] and our testing data [[2]]. Also, as you can see from the
console output, the training/testing split is approximately 70%
training, 30% testing.</p>
<p>We can now run our random forest model with the spatial
blocks/folds.</p>
<pre class="r"><code># Run a RandomForest model with default setting and spatial folds
set.seed(1)
rf_sbcv &lt;- train(method = &#39;RF&#39;, data = SWDdata, folds = spat_blocks2)</code></pre>
<p>Run the model evaluation metrics:</p>
<pre class="r"><code># Check the overall AUC and TSS values
paste0(&#39;Testing AUC: &#39;, round(SDMtune::auc(rf_sbcv, test = TRUE),2))</code></pre>
<pre><code>## [1] &quot;Testing AUC: 0.75&quot;</code></pre>
<pre class="r"><code>paste0(&#39;Testing TSS: &#39;, round(SDMtune::tss(rf_sbcv, test = TRUE),2))</code></pre>
<pre><code>## [1] &quot;Testing TSS: 0.42&quot;</code></pre>
<p>As you can see, our evaluation metrics suggest the spatial fold
models perform poorer (AUC = 0.75; TSS = 0.42) than the random fold
models (AUC = 0.86; TSS = 0.64). What’s important to note though is that
this is a far more realistic output.</p>
<p>We can also extract the individual AUC results and overall Receiver
Operator Charateristic (ROC) curve for each of the 4 folds/models. To do
this, we will load in custom functions from source to calculate the
specificity and sensitivity scores and AUC for each model:</p>
<pre class="r"><code># Extract the ROC curve and AUC values for each model
source(&#39;scripts/functions/extract_roc_vals.R&#39;)
spec_sens_vals &lt;- extract_spec_sens_vals(rf_sbcv, spat_blocks2, SWDdata)
auc_vals &lt;- extract_auc_vals(rf_sbcv, spat_blocks2, SWDdata)
auc_vals$label &lt;- paste0(auc_vals$model_no, &quot;: &quot;, round(auc_vals$auc,2))</code></pre>
<p>We can now plot out each ROC curve together with its AUC score.</p>
<pre class="r"><code># ROC curves with AUC values for each model 
ggplot(data = spec_sens_vals) +
  geom_abline(aes(slope = 1, intercept = 0), lty = 2) +
  geom_path(aes(x = 1- specificities, y = sensitivities, group = model_no, col = as.factor(model_no)), alpha = 0.8) +
  scale_colour_viridis_d(name = &#39;Model no. &amp; AUC&#39;,
                         labels = auc_vals$label) +
  labs(x = &#39;False Positive Rate&#39;, y = &#39;True Positive Rate&#39;) +
  geom_text(aes(x = 0.15, y = 0.95), label = paste0(&#39;Overall testing AUC: &#39;, round(SDMtune::auc(rf_sbcv, test = TRUE),2)), size = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.position = c(0.8, 0.25),
        legend.title = element_text(size = 8),
        legend.text = element_text(size = 7))</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/rf_sbcv_auc_plot.png&#39;,
       width = 6, height = 5, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
</div>
</div>
<div id="variable-importance" class="section level4">
<h4>Variable importance</h4>
<p>To determine which environmental covariates had the greatest
influence on the modeled distribution of our species, we can use
calculate the variable importance. There are many ways to do this and
different models have different approaches (e.g. jackknife with MaxEnt).
This function randomly permutes one variable at a time and calculates
the decrease in training AUC values. The results are normalised to
percentages.</p>
<pre class="r"><code># VI for the spatial fold RF model
vi_rf_sbcv &lt;- varImp(rf_sbcv)
plotVarImp(vi_rf_sbcv)</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>These results suggest that the <em>Max temp. of the warmest
month</em> and <em>Annual precipitation</em> are the most important
variables in our model. Remember to consider the collinearity
relationships with the variables we excluded earlier. For example
mean_t_warm_q (0.96), mean_t_wet_q (0.95), mean_t_dry_q (0.88),
mean_ann_t (0.87), etc. are all highly correlated with <em>Max temp. of
the warmest month</em> and would likely provide a similar result!</p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/rf_sbcv_vi.png&#39;,
       width = 6, height = 5, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
</div>
<div id="response-curves" class="section level4">
<h4>Response curves</h4>
<p>We can also plot out the non-linear response of our species to each
environmental covariate when all other variables are set to their mean
values (we can change this to other summary values using
<code>fun =</code>). Let’s take a look at our top 2 variables.</p>
<pre class="r"><code>plotResponse(rf_sbcv, var = &quot;max_t_warm_m&quot;, marginal = TRUE, rug = TRUE) + labs(x = &#39;Max. temp. warmest month&#39;) +
plotResponse(rf_sbcv, var = &quot;ann_p&quot;, marginal = TRUE, rug = TRUE) + labs(x = &#39;Ann. precip.&#39;) </code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-39-1.png" width="960" /></p>
<p>These outputs suggest that Protea roupelliae is far more likely to be
found at lower maximum temperatures in the warmest month (i.e. it
doesn’t like extreme heat) and higher annual precipitation (i.e. it
prefers wetter areas). The confidence intervals</p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/rf_sbcv_response_curves.png&#39;,
       width = 8, height = 4, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
</div>
<div id="model-prediction" class="section level4">
<h4>Model prediction</h4>
<p>We can now predict which areas appear most suitable to our target
species across our full area of interest using predict() and our
environmental layers.</p>
<pre class="r"><code>pred &lt;- predict(rf_sbcv, data = raster::stack(cov_clean))</code></pre>
<p><code>SDMtune</code> has a handy <code>plotPred()</code> function,
which can quickly provide us with a neat output.</p>
<pre class="r"><code># using the SMDtune::plotPred can give us a nice quick map
plotPred(pred, lt = &quot;Habitat\nsuitability&quot;, colorramp = c(&quot;#2c7bb6&quot;, &quot;#abd9e9&quot;, &quot;#ffffbf&quot;, &quot;#fdae61&quot;, &quot;#d7191c&quot;))</code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>However, if we want to customise this map, we can convert the
predicted output to a data frame and plot it manually in
<code>ggplot2</code>.</p>
<pre class="r"><code># We can also customise this further in ggplot if we like
pred_df &lt;- as.data.frame(pred, xy = TRUE)

ggplot() +
  geom_sf(data = st_as_sf(sern_a), fill = &#39;white&#39;, col = NA) + 
  geom_tile(data = pred_df, aes(x = x, y = y, fill = layer, col = layer)) +
  scale_colour_viridis_c(na.value = NA, option = &#39;C&#39;, breaks = seq(0,1,0.25),limits = c(0,1)) +
  scale_fill_viridis_c(na.value = NA, option = &#39;C&#39;, breaks = seq(0,1,0.25),limits = c(0,1)) +
  geom_sf(data = st_as_sf(sern_a), fill = NA, col = &#39;black&#39;, lwd = 0.25) + 
  geom_sf(data = st_as_sf(protea_filt_pres, coords = c(&#39;lon&#39;, &#39;lat&#39;), crs = crs(sern_a)), size = 0.5, col = &#39;black&#39;, fill = &#39;white&#39;, pch = 21) +
  scale_x_continuous(limits = c(ext(cov_clean)[1], ext(cov_clean)[2]), breaks = seq(26,32,3)) + 
  scale_y_continuous(limits = c(ext(cov_clean)[3],ext(cov_clean)[4]), breaks = seq(-32,-22,5)) +
  labs(fill = &#39;Habitat\nsuitability&#39;, 
       col = &#39;Habitat\nsuitability&#39;,
       x = &#39;Longitude&#39;, y = &#39;Latitude&#39;) +
  theme_minimal() </code></pre>
<p><img src="SDMs_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<pre class="r"><code>ggsave(&#39;output/figs/SDM/rf_sbcv_hab_suit.png&#39;,
       width = 6, height = 6, dpi = &#39;retina&#39;, bg = &#39;white&#39;)</code></pre>
</div>
<div id="extra-resources-for-species-distribution-models-in-r"
class="section level4">
<h4>Extra resources for species distribution models in R</h4>
<p>The <a href="https://rspatial.org/terra/sdm/index.html">rspatial</a>
notebook has good resources on basic SDMs in R. The <a
href="https://github.com/rvalavi/blockCV">blockCV package</a> has good
resources for using of cross-validation in spatial models and an
accompanying <a
href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13107">methods
paper</a>.</p>
<p>Both the <a
href="https://sjevelazco.github.io/flexsdm/index.html">flexsdm</a> and
<a
href="https://consbiol-unibern.github.io/SDMtune/index.html">SDMtune</a>
have useful webpages for understanding more about their respective
functions and workflows.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
